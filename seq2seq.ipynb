{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Beyond text classification: Sequence-to-sequence learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A machine translation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace spa-eng/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "# !wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
    "!unzip -q spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "text_file = \"spa-eng/spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    text_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    eng_span = pd.read_pickle(f\"~/Desktop/deep_learning/MT/train_en_es/train_{i}.pkl\")\n",
    "    port_eng = pd.read_pickle(f\"~/Desktop/deep_learning/MT/train_en_pt/train_{i}.pkl\")\n",
    "    text_pairs = []\n",
    "    for en, es in zip(eng_span[\"en_sent\"] ,eng_span[\"span_sent\"]):\n",
    "        en = \"<sp2> \"+en\n",
    "        es = \"[strat] \"+es+\" [end]\"\n",
    "        text_pairs.append((en,es))\n",
    "\n",
    "    for pt, en in zip(port_eng[\"port_sent\"] ,port_eng[\"en_sent\"]):\n",
    "        pt = \"<en2> \"+pt\n",
    "        en = \"[strat] \"+en+\" [end]\"\n",
    "        text_pairs.append((pt,en))\n",
    "# text_pairs = pd.concat((eng_span[\"en_sent\"] ,eng_span[\"span_sent\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<en2> O carro de Tom está estacionado lá fora.', \"[strat] Tom's car is parked outside. [end]\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(text_pairs[:30001])\n",
    "random.shuffle(text_pairs[30001:30000*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num = int(0.2 * len(text_pairs))//2\n",
    "val_pairs = text_pairs[:val_num] + text_pairs[30001:val_num+30001]\n",
    "train_pairs = text_pairs[val_num:30001] + text_pairs[val_num+30001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_pairs) + len(train_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = text_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Vectorizing the English and Spanish text pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 22:39:33.668107: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-18 22:39:33.677003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742317773.685213    4311 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742317773.687356    4311 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-18 22:39:33.697275: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1742317775.943899    4311 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1226 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_spanish_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preparing datasets for the translation task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\n",
    "        \"english\": eng,\n",
    "        \"spanish\": spa[:, :-1],\n",
    "    }, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048)\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (16, 20)\n",
      "inputs['spanish'].shape: (16, 20)\n",
      "targets.shape: (16, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 23:23:10.562671: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Sequence-to-sequence learning with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**GRU-based encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embed_dim = 256\n",
    "latent_dim = 1024\n",
    "\n",
    "\n",
    "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
    "encoded_source = layers.Bidirectional(\n",
    "    layers.LSTM(latent_dim), merge_mode=\"sum\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**GRU-based decoder and the end-to-end model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
    "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
    "x = decoder_gru(x, initial_state=encoded_source)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "seq2seq_rnn = keras.Model([source, past_target], target_next_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'english': <tf.Tensor: shape=(16, 20), dtype=int64, numpy=\n",
      "array([[    3,    14,   131,     7,    16,   147,   146,    24,   110,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,  1278,   245,  3472,     9,   186,     7,    97, 11072,\n",
      "           30,     7,    12,   852,    25,    12,     1,    30,     7,\n",
      "          852,    25],\n",
      "       [    3,    12,    19, 14133,    71,     4,    27,   721,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,     5,   918,   162,   735,     4,  2887,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,    14,  2191,     9,  1207,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,     7,  1620,    27,     1,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,    14,    19,     1,    90,  5258,    24,   146,   129,\n",
      "           36,  3418,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,    14,    12,  1115,    63,     8,     7,     5,    19,\n",
      "          101,    24,    63,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,    14,    12,   127,     7,     4,   694,  1015,    63,\n",
      "           39,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,     1,    90,     5,     7, 10587,     9,   589,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,    71,    34,    12,    42,     1,    28,  1119,  2123,\n",
      "            1,  1974,  1978,    27,   426,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,   363,     7,  2959,   242,   646,     4,  1241,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,   967,  2597,     9,   576,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,     1,    17,     4,   102,  3320,  2564,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,    14,   123,   400,   139,   312,   134,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    3,    16,   118,   495,    12,   860,     4,    79,   611,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]])>, 'spanish': <tf.Tensor: shape=(16, 20), dtype=int64, numpy=\n",
      "array([[    2,     8,    58,    11,    66,     7,    82,   231,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,    84,    36,   233,  9386,    19,   159,   100,    36,\n",
      "         4994,   454,   100,    40,    58,   118,    40,   403,   454,\n",
      "          100,    58],\n",
      "       [    2,    40,  2978,    17,    59,     4,   702,     3,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,     6,    63,   955,    27,   644,  3450,     3,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,     8,    32,   180,   156,  4298,     3,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,    78,    92,   172,   976,     3,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,     8,   536,    38,   442,     7,    25,   175,    51,\n",
      "            5,  3121,     3,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,     8,    85,    66,     7,    25,    43,     6,   174,\n",
      "           17,     7,    25,     3,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,     8,    40,    77,    20,    41,    69,    25,    33,\n",
      "            3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,     8,   174,     6,   269,  1500,    38,   750,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,   644,    24,    74,    53,  2682,  2151,   227,     1,\n",
      "         2073,    24,   862,     7, 11808,    65,   661,     3,     0,\n",
      "            0,     0],\n",
      "       [    2,    72,   611,    72,    41,   212,    84,    33,  1504,\n",
      "            7,   760,     3,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,     8,    69,  3005,  2098,     3,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,     1,    15,    38,  1090,  2326,     3,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,     8,    66,     7,    58,   137,    70,    36,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0],\n",
      "       [    2,    11,    69,   460,    12,   739,    61,   831,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]])>} /n/n/n tf.Tensor(\n",
      "[[    8    58    11    66     7    82   231     3     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   84    36   233  9386    19   159   100    36  4994   454   100    40\n",
      "     58   118    40   403   454   100    58   118]\n",
      " [   40  2978    17    59     4   702     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    6    63   955    27   644  3450     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    8    32   180   156  4298     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   78    92   172   976     3     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    8   536    38   442     7    25   175    51     5  3121     3     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    8    85    66     7    25    43     6   174    17     7    25     3\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    8    40    77    20    41    69    25    33     3     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    8   174     6   269  1500    38   750     3     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [  644    24    74    53  2682  2151   227     1  2073    24   862     7\n",
      "  11808    65   661     3     0     0     0     0]\n",
      " [   72   611    72    41   212    84    33  1504     7   760     3     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    8    69  3005  2098     3     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    1    15    38  1090  2326     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    8    66     7    58   137    70    36     3     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   11    69   460    12   739    61   831     3     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]], shape=(16, 20), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:1387: UserWarning: Layer 'encoder_3' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Exception encountered when calling Embedding.call().\n",
      "\n",
      "\u001b[1m'dict' object has no attribute 'dtype'\u001b[0m\n",
      "\n",
      "Arguments received by Embedding.call():\n",
      "  • inputs={'english': 'tf.Tensor(shape=(16, 20), dtype=int64)', 'spanish': 'tf.Tensor(shape=(16, 20), dtype=int64)'}''\n",
      "  warnings.warn(\n",
      "/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:1387: UserWarning: Layer 'seq2_seq_with_attention_3' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Exception encountered when calling Embedding.call().\n",
      "\n",
      "\u001b[1m'dict' object has no attribute 'dtype'\u001b[0m\n",
      "\n",
      "Arguments received by Embedding.call():\n",
      "  • inputs={'english': 'tf.Tensor(shape=(16, 20), dtype=int64)', 'spanish': 'tf.Tensor(shape=(16, 20), dtype=int64)'}''\n",
      "  warnings.warn(\n",
      "/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'seq2_seq_with_attention_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling Embedding.call().\n\n\u001b[1m'dict' object has no attribute 'dtype'\u001b[0m\n\nArguments received by Embedding.call():\n  • inputs={'english': 'tf.Tensor(shape=(16, 20), dtype=int64)', 'spanish': 'tf.Tensor(shape=(16, 20), dtype=int64)'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 195\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(loss_)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Example of how you might create a dataset (you would use your actual data)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor)).shuffle(BUFFER_SIZE)\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Then you would call:\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 144\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataset, epochs, model, optimizer, loss_function)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(inp,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/n/n/n\u001b[39m\u001b[38;5;124m\"\u001b[39m,targ)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m--> 144\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Calculate loss (targ[:, 1:] is the target without start token)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(targ[:, \u001b[38;5;241m1\u001b[39m:], predictions)\n",
      "File \u001b[0;32m~/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[11], line 105\u001b[0m, in \u001b[0;36mSeq2SeqWithAttention.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    102\u001b[0m inp, targ \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m    104\u001b[0m enc_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39minitialize_hidden_state()\n\u001b[0;32m--> 105\u001b[0m enc_output, enc_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m dec_hidden \u001b[38;5;241m=\u001b[39m enc_hidden\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Start token ID (assuming it's 1, adjust as needed)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m, in \u001b[0;36mEncoder.call\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[0;32m---> 17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     output, state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(x, initial_state\u001b[38;5;241m=\u001b[39mhidden)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, state\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling Embedding.call().\n\n\u001b[1m'dict' object has no attribute 'dtype'\u001b[0m\n\nArguments received by Embedding.call():\n  • inputs={'english': 'tf.Tensor(shape=(16, 20), dtype=int64)', 'spanish': 'tf.Tensor(shape=(16, 20), dtype=int64)'}"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights\n",
    "\n",
    "\n",
    "class Seq2SeqWithAttention(tf.keras.Model):\n",
    "    def __init__(self, inp_vocab_size, targ_vocab_size, embedding_dim, \n",
    "                 enc_units, dec_units, batch_sz, targ_lang_tokenizer):\n",
    "        super(Seq2SeqWithAttention, self).__init__()\n",
    "        self.encoder = Encoder(inp_vocab_size, embedding_dim, enc_units, batch_sz)\n",
    "        self.decoder = Decoder(targ_vocab_size, embedding_dim, dec_units, batch_sz)\n",
    "        self.targ_lang_tokenizer = targ_lang_tokenizer\n",
    "        self.batch_sz = batch_sz\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        # Unpack the inputs\n",
    "        inp, targ = inputs\n",
    "\n",
    "        enc_hidden = self.encoder.initialize_hidden_state()\n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        # Start token ID (assuming it's 1, adjust as needed)\n",
    "        start_token_id = tf.constant([self.targ_lang_tokenizer.word_index['<start>']] * self.batch_sz)\n",
    "        start_token_id = tf.reshape(start_token_id, (self.batch_sz, 1))\n",
    "        \n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        dec_input = start_token_id  # Start with start token\n",
    "        \n",
    "        # Initialize the outputs container\n",
    "        outputs = []\n",
    "        \n",
    "        # For each timestep in the target sequence\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # Passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            outputs.append(predictions)\n",
    "            \n",
    "            if training:\n",
    "                # Teacher forcing - use actual target tokens as next input\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "            else:\n",
    "                # Use predictions as next input\n",
    "                predicted_id = tf.argmax(predictions, axis=1)\n",
    "                dec_input = tf.expand_dims(predicted_id, 1)\n",
    "        \n",
    "        return tf.stack(outputs, axis=1)  # Shape: [batch_size, targ_seq_len-1, targ_vocab_size]\n",
    "\n",
    "# Example of how to use the model for training\n",
    "def train_model(dataset, epochs, model, optimizer, loss_function):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for (batch, (inp, targ)) in enumerate(dataset):\n",
    "            print(inp,\"/n/n/n\",targ)\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model((inp, targ), training=True)\n",
    "                \n",
    "                # Calculate loss (targ[:, 1:] is the target without start token)\n",
    "                loss = loss_function(targ[:, 1:], predictions)\n",
    "                \n",
    "            # Apply gradients\n",
    "            variables = model.trainable_variables\n",
    "            gradients = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(gradients, variables))\n",
    "            \n",
    "            total_loss += loss\n",
    "            \n",
    "        print(f'Epoch {epoch+1} Loss {total_loss/len(dataset):.4f}')\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # These values would be set based on your dataset\n",
    "    BATCH_SIZE = 64\n",
    "    embedding_dim = 256\n",
    "    units = 1024\n",
    "    \n",
    "    # Example tokenizers and vocab sizes (these would come from preprocessing your data)\n",
    "    inp_lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    targ_lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    \n",
    "    # After fitting tokenizers on your data:\n",
    "    inp_vocab_size = len(inp_lang_tokenizer.word_index) + 1\n",
    "    targ_vocab_size = len(targ_lang_tokenizer.word_index) + 1\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Seq2SeqWithAttention(inp_vocab_size, targ_vocab_size, \n",
    "                                embedding_dim, units, units, \n",
    "                                BATCH_SIZE, targ_lang_tokenizer)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    \n",
    "    def loss_function(real, pred):\n",
    "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "        loss_ = loss_object(real, pred)\n",
    "        \n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        \n",
    "        return tf.reduce_mean(loss_)\n",
    "    \n",
    "    # Example of how you might create a dataset (you would use your actual data)\n",
    "    # dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor)).shuffle(BUFFER_SIZE)\n",
    "    # dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    \n",
    "    # Then you would call:\n",
    "    train_model(train_ds, 5, model, optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Bidirectional LSTM layer\n",
    "        self.bilstm = tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(self.enc_units,\n",
    "                                return_sequences=True,\n",
    "                                return_state=True,\n",
    "                                recurrent_initializer='glorot_uniform')\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Bidirectional LSTM returns outputs and states from both directions\n",
    "        output, forward_h, forward_c, backward_h, backward_c = self.bilstm(x)\n",
    "        \n",
    "        # Concatenate the forward and backward states\n",
    "        state_h = tf.concat([forward_h, backward_h], axis=-1)\n",
    "        state_c = tf.concat([forward_c, backward_c], axis=-1)\n",
    "        \n",
    "        return output, state_h, state_c\n",
    "\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Use LSTM for decoder (note: not bidirectional in decoder)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.dec_units * 2,  # *2 because encoder output is bidirectional\n",
    "                                        return_sequences=True,\n",
    "                                        return_state=True,\n",
    "                                        recurrent_initializer='glorot_uniform')\n",
    "                                        \n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention = BahdanauAttention(self.dec_units * 2)\n",
    "\n",
    "    def call(self, x, hidden_state, cell_state, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size*2)\n",
    "        context_vector, attention_weights = self.attention(hidden_state, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size*2)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the LSTM\n",
    "        output, state_h, state_c = self.lstm(x, initial_state=[hidden_state, cell_state])\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size*2)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state_h, state_c, attention_weights\n",
    "\n",
    "\n",
    "class Seq2SeqWithAttention(tf.keras.Model):\n",
    "    def __init__(self, inp_vocab_size, targ_vocab_size, embedding_dim, \n",
    "                enc_units, dec_units, batch_sz, targ_lang_tokenizer):\n",
    "        super(Seq2SeqWithAttention, self).__init__()\n",
    "        self.encoder = Encoder(inp_vocab_size, embedding_dim, enc_units, batch_sz)\n",
    "        self.decoder = Decoder(targ_vocab_size, embedding_dim, dec_units, batch_sz)\n",
    "        self.targ_lang_tokenizer = targ_lang_tokenizer\n",
    "        self.batch_sz = batch_sz\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        # Unpack the inputs\n",
    "        inp, targ = inputs\n",
    "\n",
    "        # Encoder output\n",
    "        enc_output, enc_hidden, enc_cell = self.encoder(inp)\n",
    "\n",
    "        # Initialize decoder state with encoder final states\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_cell = enc_cell\n",
    "        \n",
    "        # Start token ID (assuming it's 1, adjust as needed)\n",
    "        start_token_id = tf.constant([self.targ_lang_tokenizer.word_index['<start>']] * self.batch_sz)\n",
    "        start_token_id = tf.reshape(start_token_id, (self.batch_sz, 1))\n",
    "        \n",
    "        # Initialize the outputs container\n",
    "        outputs = []\n",
    "        \n",
    "        # For each timestep in the target sequence\n",
    "        dec_input = start_token_id  # Start with start token\n",
    "        \n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # Passing enc_output to the decoder\n",
    "            predictions, dec_hidden, dec_cell, _ = self.decoder(\n",
    "                dec_input, dec_hidden, dec_cell, enc_output)\n",
    "            \n",
    "            outputs.append(predictions)\n",
    "            \n",
    "            if training:\n",
    "                # Teacher forcing - use actual target tokens as next input\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "            else:\n",
    "                # Use predictions as next input\n",
    "                predicted_id = tf.argmax(predictions, axis=1)\n",
    "                dec_input = tf.expand_dims(predicted_id, 1)\n",
    "        \n",
    "        return tf.stack(outputs, axis=1)  # Shape: [batch_size, targ_seq_len-1, targ_vocab_size]\n",
    "\n",
    "    def initialize_states(self, batch_size):\n",
    "        # This method can be used during inference to initialize states\n",
    "        return tf.zeros((batch_size, self.decoder.dec_units * 2)), tf.zeros((batch_size, self.decoder.dec_units * 2))\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(dataset, epochs, model, optimizer, loss_function):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for (batch, (inp, targ)) in enumerate(dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model((inp, targ), training=True)\n",
    "                \n",
    "                # Calculate loss (targ[:, 1:] is the target without start token)\n",
    "                loss = loss_function(targ[:, 1:], predictions)\n",
    "                \n",
    "            # Apply gradients\n",
    "            variables = model.trainable_variables\n",
    "            gradients = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(gradients, variables))\n",
    "            \n",
    "            total_loss += loss\n",
    "            \n",
    "        print(f'Epoch {epoch+1} Loss {total_loss/len(dataset):.4f}')\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # These values would be set based on your dataset\n",
    "    BATCH_SIZE = 64\n",
    "    embedding_dim = 256\n",
    "    units = 512  # Each direction will have this many units\n",
    "    \n",
    "    # Example tokenizers and vocab sizes (these would come from preprocessing your data)\n",
    "    inp_lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    targ_lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    \n",
    "    # After fitting tokenizers on your data:\n",
    "    inp_vocab_size = len(inp_lang_tokenizer.word_index) + 1\n",
    "    targ_vocab_size = len(targ_lang_tokenizer.word_index) + 1\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Seq2SeqWithAttention(inp_vocab_size, targ_vocab_size, \n",
    "                                embedding_dim, units, units, \n",
    "                                BATCH_SIZE, targ_lang_tokenizer)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_object = tf.keras.losses.SparseCategori\n",
    "    calCrossentropy(from_logits=True, reduction='none')\n",
    "    \n",
    "    def loss_function(real, pred):\n",
    "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "        loss_ = loss_object(real, pred)\n",
    "        \n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        \n",
    "        return tf.reduce_mean(loss_)\n",
    "    \n",
    "    # Example of creating a dataset (use your actual data)\n",
    "    # dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor)).shuffle(BUFFER_SIZE)\n",
    "    # dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    \n",
    "    # Call the training function\n",
    "    # train_model(dataset, EPOCHS, model, optimizer, loss_function)\n",
    "\n",
    "\n",
    "# Inference function (for generating translations)\n",
    "def translate(model, sentence, max_length=40):\n",
    "    # Preprocess the sentence (tokenize, pad, etc.)\n",
    "    # ...\n",
    "    \n",
    "    # Initialize decoder input and states\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "    dec_hidden, dec_cell = model.initialize_states(1)\n",
    "    \n",
    "    # Get encoder output\n",
    "    inp_tensor = tf.convert_to_tensor([sentence])\n",
    "    enc_output, enc_hidden, enc_cell = model.encoder(inp_tensor)\n",
    "    \n",
    "    dec_hidden = enc_hidden\n",
    "    dec_cell = enc_cell\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for t in range(max_length):\n",
    "        predictions, dec_hidden, dec_cell, attention_weights = model.decoder(\n",
    "            dec_input, dec_hidden, dec_cell, enc_output)\n",
    "        \n",
    "        # Get the predicted ID\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        # Append to result\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            break\n",
    "        result.append(targ_lang_tokenizer.index_word[predicted_id])\n",
    "        \n",
    "        # Use the predicted ID as the next input\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,493,952</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)]            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ spanish[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">18,882,560</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spanish[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)             │            │ attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">61,455,000</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,840,000\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │ \u001b[38;5;34m10,493,952\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m2048\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m)]            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,840,000\u001b[0m │ spanish[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m18,882,560\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m2048\u001b[0m)             │            │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ spanish[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │ \u001b[38;5;34m2048\u001b[0m)             │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m4096\u001b[0m)             │            │ attention_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m4096\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m61,455,000\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">295,534,538</span> (1.10 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m295,534,538\u001b[0m (1.10 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,511,512</span> (375.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,511,512\u001b[0m (375.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,023,026</span> (751.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m197,023,026\u001b[0m (751.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(seq2seq_rnn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training our recurrent sequence-to-sequence model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 23:29:51.643424: W tensorflow/core/framework/op_kernel.cc:1829] INVALID_ARGUMENT: required broadcastable shapes\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_1_1/attention_1_1/sub defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_12844/4134485903.py\", line 5, in <module>\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 57, in train_step\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 908, in __call__\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/models/functional.py\", line 637, in call\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 908, in __call__\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/attention/attention.py\", line 233, in call\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/attention/attention.py\", line 180, in _apply_scores\n\nrequired broadcastable shapes\n\t [[{{node functional_1_1/attention_1_1/sub}}]] [Op:__inference_multi_step_on_iterator_9552]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m seq2seq_rnn\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      2\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[43mseq2seq_rnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_1_1/attention_1_1/sub defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_12844/4134485903.py\", line 5, in <module>\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 57, in train_step\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 908, in __call__\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/models/functional.py\", line 637, in call\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 908, in __call__\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/attention/attention.py\", line 233, in call\n\n  File \"/home/admin/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/attention/attention.py\", line 180, in _apply_scores\n\nrequired broadcastable shapes\n\t [[{{node functional_1_1/attention_1_1/sub}}]] [Op:__inference_multi_step_on_iterator_9552]"
     ]
    }
   ],
   "source": [
    "seq2seq_rnn.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "seq2seq_rnn.fit(train_ds, epochs=5, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Translating new sentences with our RNN encoder and decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "[start] muchas palabras son [UNK] y [UNK] [end]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization([decoded_sentence])\n",
    "        next_token_predictions = seq2seq_rnn.predict(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "# test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "# for _ in range(20):\n",
    "#     input_sentence = random.choice(test_eng_texts)\n",
    "#     print(\"-\")\n",
    "#     print(input_sentence)\n",
    "#     print(decode_sequence(input_sentence))\n",
    "print(decode_sequence(\"<sp2> O mercúrio é também conhecido como azougue.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Sequence-to-sequence learning with Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The Transformer decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `TransformerDecoder`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        else:\n",
    "            padding_mask = mask\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Putting it all together: A Transformer for machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**PositionalEmbedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**End-to-end Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m num_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      5\u001b[0m encoder_inputs \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mPositionalEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n\u001b[1;32m      9\u001b[0m decoder_inputs \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspanish\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[134], line 20\u001b[0m, in \u001b[0;36mPositionalEmbedding.compute_mask\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_mask\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training the sequence-to-sequence Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      2\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      5\u001b[0m transformer\u001b[38;5;241m.\u001b[39mfit(train_ds, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mval_ds)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformer' is not defined"
     ]
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Translating new sentences with our Transformer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter11_part04_sequence-to-sequence-learning.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
